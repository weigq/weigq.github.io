<!doctypehtml><html lang=en><meta content="text/html; charset=UTF-8"http-equiv=content-type><meta content="width=device-width,initial-scale=1,maximum-scale=1"name=viewport><meta content="Guoqiang Wei"name=author><title>Guoqiang Wei</title><link href=images/icon.png rel=icon type=image/png><link href="https://fonts.googleapis.com/css?family=Noto Sans"rel=stylesheet><link href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.1/css/all.min.css rel=preload as=style onload='this.rel="stylesheet"'><link href=https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.2/css/academicons.min.css rel=preload as=style onload='this.rel="stylesheet"'><link href=web_assets/main.min.css rel=preload as=style onload='this.rel="stylesheet"'><link href=web_assets/main.min.js rel=preload as=script><script src=https://buttons.github.io/buttons.js async defer></script><div class=main-body><div class=top-title><div style=text-align:center><p>Guoqiang Wei<p class=top-sub-title>é­å›½å¼º</div></div><div class=top-intro><div class=top-intro-left><p>I am currently a researcher at ByteDance AI Lab (<img src=images/bytedance.png width=22px style=vertical-align:text-bottom>).<p>Before that, I received my Ph.D. degree in Electronic Engineering & Information Science (EEIS), under the joint Ph.D. program between <a href=http://ustc.edu/ >USTC</a> and Microsoft Research Asia <a href=https://www.microsoft.com/en-us/research/lab/microsoft-research-asia/ >(MSRA)</a>, luckily advised by <a href="https://scholar.google.com/citations?user=djk5l-4AAAAJ&hl=zh-CN">Dr. Yan Lu</a> (<img src=images/microsoft-mini.svg width=18px style=vertical-align:initial>), <a href="https://scholar.google.com/citations?user=_cUfvYQAAAAJ&hl=en">Prof. Wenjun Zeng</a> (<img src=images/microsoft-mini.svg width=18px style=vertical-align:initial>) and <a href="https://scholar.google.com/citations?user=1ayDJfsAAAAJ&hl=en">Prof. Zhibo Chen</a> (<img src=images/ustc.png width=24px style=vertical-align:text-top>). I was a long-term research intern at MSRA, and collaborated closely with <a href="https://scholar.google.com/citations?user=X7M0I8kAAAAJ&hl=en">Dr. Zhizheng Zhang</a> (<img src=images/microsoft-mini.svg width=18px style=vertical-align:initial>) and <a href="https://scholar.google.com/citations?user=XZugqiwAAAAJ&hl=en">Dr. Cuiling Lan</a> (<img src=images/microsoft-mini.svg width=18px style=vertical-align:initial>).<br><p style=color:rgba(255,0,0,.86);font-style:italic>We are hiring interns for video generation, video understanding and multi-modality learning.</p><span style=font-style:italic;font-size:.8em><i class="fa-calendar-days fa-solid"></i> last update @Sep. 2023</span></div><div class=top-intro-right><div><img src=images/weigq.jpg style=border-radius:24px class=avatar title="Profile photo"></div><div class=click-icon><a href="mailto:weiguoqiang.9@bytedance.com; weigq1234@gmail.com"><i class="fa-lg fa fa-envelope"title=Email></i></a> Â |Â  <a href="https://scholar.google.com/citations?hl=en&user=TxeZUTgAAAAJ"><i class="ai ai-google-scholar-square ai-lg"title="Google scholar"></i><sup></sup></a> Â |Â  <a href=https://github.com/weigq><i class="fa-lg fa-github fab"title=Github></i></a> Â |Â  <a href=https://www.linkedin.com/in/guoqiang-wei-535507145/ ><i class="fa-lg fa-brands fa-linkedin"></i></a></div></div></div><div class=research-body><h1>Research</h1><div class=h-line></div><div class=research-content>ğŸ‘‰ <a href="https://scholar.google.com/citations?hl=en&user=TxeZUTgAAAAJ">Google scholar list</a></div></div><div class=exp-body><h1>Experience</h1><div class=h-line></div><div class=exp-content><div class=exp-item style=margin-bottom:10pt><div class=exp-item-left style=width:15%><img src=images/bytedance.png width=50%></div><div class=exp-item-right><div class=exp-item-right-content><span>2023-06~present:</span>Â  Researcher at ByteDance AI Lab</div></div></div><div class=exp-item style=margin-bottom:10pt><div class=exp-item-left style=width:15%><img src=images/bytedance.png width=50%></div><div class=exp-item-right><div class=exp-item-right-content><span>2023-03~2023-06:</span>Â  Research intern at ByteDance AI Lab</div></div></div><div class=exp-item style=margin-bottom:10pt><div class=exp-item-left style=width:15%><img src=images/microsoft-mini.svg width=50%></div><div class=exp-item-right><div class=exp-item-right-content><span>2019-07~2023-03:</span>Â  Research intern at MSRA</div></div></div><div class=exp-item style=margin-bottom:10pt><div class=exp-item-left style=width:15%><img src=images/ustc.png width=50%></div><div class=exp-item-right><div class=exp-item-right-content><span>2018-09~2023-06:</span>Â  PhD in EE at USTC & MSRA</div></div></div><div class=exp-item style=margin-bottom:10pt><div class=exp-item-left style=width:15%><img src=images/microsoft-mini.svg width=50%></div><div class=exp-item-right><div class=exp-item-right-content><span>2017-07~2018-06:</span>Â  Research intern at MSRA</div></div></div><div class=exp-item style=margin-bottom:10pt><div class=exp-item-left style=width:15%><img src=images/ustc.png width=50%></div><div class=exp-item-right><div class=exp-item-right-content><span>2014-09~2018-06:</span>Â  Bachelor in EE at USTC</div></div></div></div></div><div class=exp-body style=padding-bottom:0><h1>Professional Activities</h1><div class=h-line></div><div class=exp-content><div class=exp-item><div class=exp-item-left style=width:100%;text-align:left;padding-left:1px><div>Reviewer[C]: Â Â Â Â  CVPR, ICCV, ECCV, NuerIPS, ICLR, AAAI</div><div>Reviewer[J]: Â Â Â Â Â  IJCV, Pattern Recognition, TCSVT</div></div></div></div></div><div class=exp-body><h1>Misc</h1><div class=h-line></div><div class=exp-content><div class=exp-item style=margin-bottom:20px><div class=exp-item-left style=text-align:left;display:inline;width:35%><a href=https://github.com/Microsoft/ActiveMLP aria-label="Star Microsoft/ActiveMLP on GitHub"class=github-button data-icon=octicon-star data-show-count=true></a> <a href=https://github.com/microsoft/ActiveMLP>ActiveMLP</a></div><div class=exp-item-right><div class=exp-item-right-content>Implementation of ActiveMLP for classification, detection and segmentation.</div></div></div><div class=exp-item style=margin-bottom:20px><div class=exp-item-left style=text-align:left;display:inline;width:35%><a href=https://github.com/weigq/3d_pose_baseline_pytorch aria-label="Star weigq/3d_pose_baseline_pytorch on GitHub"class=github-button data-icon=octicon-star data-show-count=true></a> <a href=https://github.com/weigq/3d_pose_baseline_pytorch>3d_pose</a></div><div class=exp-item-right><div class=exp-item-right-content>A 3D human pose estimation baseline with Pytorch.</div></div></div><div class=exp-item style=margin-bottom:20px><div class=exp-item-left style=text-align:left;display:inline;width:35%><a href=https://github.com/microsoft/UDA aria-label="Star microsoft/UDA on GitHub"class=github-button data-icon=octicon-star data-show-count=true></a> <a href=https://github.com/microsoft/UDA>UDA</a></div><div class=exp-item-right><div class=exp-item-right-content>A unified UDA framework with Pytorch.</div></div></div><div class=exp-item style=margin-bottom:20px><div class=exp-item-left style=text-align:left;display:inline;width:35%><a href=https://github.com/weigq/iclr2023_stats aria-label="Star weigq/iclr2023_stats on GitHub"class=github-button data-icon=octicon-star data-show-count=true></a> <a href=https://guoqiangwei.xyz/iclr2023_stats/iclr2023_submissions.html>iclr2023_stats</a></div><div class=exp-item-right><div class=exp-item-right-content>Statistics of ICLR 2023 submissions.</div></div></div><div class=exp-item style=margin-bottom:20px><div class=exp-item-left style=text-align:left;display:inline;width:35%><a href=https://github.com/weigq/iclr2022_stats aria-label="Star weigq/iclr2022_stats on GitHub"class=github-button data-icon=octicon-star data-show-count=true></a> <a href=https://guoqiangwei.xyz/iclr2022_stats/iclr2022_submissions.html>iclr2022_stats</a></div><div class=exp-item-right><div class=exp-item-right-content>Statistics of ICLR 2022 submissions.</div></div></div><div class=exp-item style=margin-bottom:20px><div class=exp-item-left style=text-align:left;display:inline;width:35%><a href=https://github.com/weigq/neurips2021_stats aria-label="Star weigq/neurips2021_stats on GitHub"class=github-button data-icon=octicon-star data-show-count=true></a> <a href=https://guoqiangwei.xyz/neurips2021_stats/neurips2021_submissions.html>neurips2021_stats</a></div><div class=exp-item-right><div class=exp-item-right-content>Statistics of NeurIPS 2021 submissions.</div></div></div><div class=exp-item style=margin-bottom:20px><div class=exp-item-left style=text-align:left;display:inline;width:35%><img src=images/openreview.png width=15%></div><div class=exp-item-right><div class=exp-item-right-content>A browser extension (<a href="https://chrome.google.com/webstore/detail/openreview-quicklook/efoabjckcjahofacmgekfhjadpjlmcap?hl=en&authuser=0"><img src=images/chrome.png width=18px alt="chrome extension"></a>/<a href=https://microsoftedge.microsoft.com/addons/detail/openreview-quicklook/filopbleifodbgnhaelacfmddhookhka><img src=images/edge.png width=18px alt="chrome extension"></a>) for OpenReview.</div></div></div></div></div><div class=footer><i class="fa-copyright far"></i> Guoqiang Wei. Website <a href=https://github.com/weigq/weigq.github.io>source code</a>.</div></div><button id=myBtn onclick=topFunction() title="Go to top">Top</button><script src=web_assets/main.js></script>
